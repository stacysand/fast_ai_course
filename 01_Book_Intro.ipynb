{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51eab40e-6f6e-4dd8-9fdc-31766ff4684d",
   "metadata": {},
   "source": [
    "# 01_Book_Intro\n",
    "\n",
    "**Content:**\n",
    "1) Download a dataset\n",
    "2) Download a trained model\n",
    "3) Feed a new example to the model to check results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0966bd-74df-46d4-bc18-16e8764b1e86",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "249f3a97-1f61-43ca-a1d3-6fb775bf32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *  #  to get fns and classes needed to create a wide variety of computer vision models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591155ca-21d4-4696-98d5-ad36eb782a57",
   "metadata": {},
   "source": [
    "# A complete system for creating and training NN for recognizing cats vs dogs\n",
    "## Download a dataset, download and luanch a pretrained model\n",
    "What does the code do:\n",
    "1) A dataset \"the Oxford-IIIT Pet Dataset\" (https://www.google.com/url?q=http%3A%2F%2Fwww.robots.ox.ac.uk%2F%7Evgg%2Fdata%2Fpets%2F) is downloaded from the fast.ai datasets collection to the GPU server, and then extracted. The dataset contains 7,349 images of cats and dogs.\n",
    "2) A pretrained model (trained on 1.3 million images) is downloaded from the internet.  \n",
    "(These two steps only need to be run once on GPU server. If you run the cell again, it will use the dataset and model that have already been downloaded, rather than downloading them again)\n",
    "3) The pretrained model is fine-tuned using the latest advances in transfer learning, to create a model that is specially customized for recognizing dogs and cats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89e27259-f525-45ca-bff2-3d0a1b20d78c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.167203</td>\n",
       "      <td>0.019018</td>\n",
       "      <td>0.007442</td>\n",
       "      <td>02:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>error_rate</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.060676</td>\n",
       "      <td>0.037679</td>\n",
       "      <td>0.009472</td>\n",
       "      <td>03:48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# download and extract the dataset\n",
    "path = untar_data(URLs.PETS)/'images'\n",
    "\n",
    "# fn for labeling cats\n",
    "def is_cat(x): return x[0].isupper()\n",
    "\n",
    "# define the kind and structure of the dataset\n",
    "dls = ImageDataLoaders.from_name_func(\n",
    "    path, get_image_files(path), valid_pct=0.2, seed=42,\n",
    "    label_func=is_cat, item_tfms=Resize(224))\n",
    "\n",
    "# create CNN (specify architecture, data, and metrics)\n",
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "\n",
    "# perform fine-tuning\n",
    "learn.fine_tune(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af5038a-dcc0-424b-ac69-6e223cb478d4",
   "metadata": {},
   "source": [
    "_______________\n",
    "Comment:\n",
    "- path = returns a Path object with the extracted location of the dataset\n",
    "- is_cat(x) = a fn which labels cats based on a filename rule provided by the dataset creators. In the Pet dataset, each image is labeled using its filename (e.g., \"great_pyrenees_173.jpg\"): it starts with an uppercase letter if the image is a cat, and a lowercase letter otherwise. is_cat returns x[0].isupper(), which evaluates to True if the first letter is uppercase (i.e., it's a cat).\n",
    "\n",
    "dls\n",
    "- dls = data loaders. tells fastai what kind of dataset we have and how it is structured.\n",
    "- ImageDataLoaders = one of the different classes for different kinds of deep learning datasets and problems. The first part of the class name is (and generally) the type of data (e.g., image or text)\n",
    "- from_name_func() =  tells fastai how to get labels from the filenames (which means that labels can be extracted using a function applied to the filename), and passing is_cat.\n",
    "- path = where to find the data\n",
    "- valid_pct = tells fastai to hold out 20% of the data (validation set), another 80% is training set. By default, the 20% that is held out is selected randomly.\n",
    "- seed = sets the random seed to the same value every time we run this code, which means we get the same validation set every time we run itâ€”this way, if we change our model and retrain it, we know that any differences are due to the changes to the model, not due to having a different random validation set.\n",
    "- label_func=is_cat = tells fastai how to get the labels from the dataset -  to use the is_cat function we just defined.\n",
    "- item_tfms = defines the Transforms that we need. A Transform contains code that is applied automatically during training; fastai includes many predefined Transforms. There are two kinds:  \n",
    "  item_tfms are applied to each item (in this case, each item is resized to a 224-pixel square)  \n",
    "  batch_tfms are applied to a batch of items at a time using the GPU, so they're particularly fast  \n",
    "  Why 224 pixels? This is the standard size for historical reasons (old pretrained models require this size exactly), but you can pass pretty much anything. If you increase the size, you'll often get a model with better results (since it will be able to focus on more details), but at the price of speed and memory consumption.\n",
    "\n",
    "learn\n",
    "- dls = dataloaders' object, our data\n",
    "- resnet34 = the model, the one of the fastai's build-in models. there are some standard architectures that work most of the time, and in this case we're using one called ResNet. The 34 in resnet34 refers to the number of layers in this variant of the architecture (other options are 18, 50, 101, and 152).\n",
    "- metrics = a metric is a fn that measures the quality of the model's predictions using the validation set. In this case, we're using error_rate, which is a fn provided by fastai that tells you what percentage of images in the validation set are being classified incorrectly. Another common metric for classification is accuracy (which is just 1.0 - error_rate).\n",
    "- vision_learner() = also has a parameter pretrained, which defaults to True. When using a pretrained model, vision_learner will remove the last layer, since that is always specifically customized to the original training task (i.e. ImageNet dataset classification), and replace it with one or more new layers with randomized weights, of an appropriate size for the dataset you are working with. This last part of the model is known as the head.\n",
    "\n",
    "learn.fine_tune\n",
    "- fine_tune() = since we've started with a pretrained model, we use fine_tune instead of the fit() because we don't want to throw away all those capabilities that were already trained.\n",
    "_______________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c80979-7309-4a7b-9566-ec6519bea921",
   "metadata": {},
   "source": [
    "## Check the results of the pretrained model\n",
    "Let's check that this model actually works.\n",
    "1) Upload an image of a dog or a cat (make sure that it is a clear photo of a single dog or a cat, and not a line drawing, cartoon, or similar):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74cd98b8-dae4-4db4-a8f5-b6718797817b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c10356b40004f29a3a267ed1e00b297",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), description='Upload')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload through the upload button:\n",
    "import ipywidgets as widgets\n",
    "uploader = widgets.FileUpload()\n",
    "uploader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "641d1125-6474-4c1b-be94-ff882b71dd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or if we can't click an upload button, we can fake it:\n",
    "from types import SimpleNamespace\n",
    "uploader = SimpleNamespace(data = ['/Users/hela/Downloads/cat.jpeg']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "719d6288-7e78-4cd8-92dc-049c79495cd5",
   "metadata": {},
   "source": [
    "2) Pass the uploaded file to the model. NN will tell you whether it thinks it is a dog or a cat, and how confident it is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "579af3b3-ecbb-4a17-8c1e-2b623fe7688f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is this a cat?: True.\n",
      "Probability it's a cat: 1.000000\n"
     ]
    }
   ],
   "source": [
    "img = PILImage.create(uploader.data[0])\n",
    "is_cat,_,probs = learn.predict(img)\n",
    "print(f\"Is this a cat?: {is_cat}.\")\n",
    "print(f\"Probability it's a cat: {probs[1].item():.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
