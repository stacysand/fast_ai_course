{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66ed78c7-3d10-4a0d-9626-1160d1ca9967",
   "metadata": {},
   "source": [
    "# 07_Lecture_CollaborativeFiltering\n",
    "\n",
    "look at what products the current user has used or liked, find other users that have used or liked similar products, and then recommend other products that those users have used or liked.\n",
    "\n",
    "This Lecture is progressively biult on the following Lectures:\n",
    "- Lecture 07 (last 40 min)\n",
    "- Lecture 08\n",
    "\n",
    "**Comments:**\n",
    "- Computational Linear Algebra for Coders (for PCA and others) (https://github.com/fastai/numerical-linear-algebra)  \n",
    "- To look at the course code: collab_learner??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71820f82-872f-47b5-ae42-55f5830c1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import *\n",
    "from fastai.tabular.all import *\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec8a0fc-71c2-47ff-8ab4-e3ffcc3f9280",
   "metadata": {},
   "source": [
    "### Data\n",
    "Data is from MovieLens available through the usual fastai function.\n",
    "\n",
    "The main table is in the file u.data. It is tab-separated and the columns are, respectively user, movie, rating, and timestamp. Since those names are not encoded, we need to indicate them when reading the file with Pandas. Also, the table u.item contains the correspondence of IDs to titles. Open the table and take a look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69368a2e-8820-4141-95b4-ac5057e2aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user  movie  rating  timestamp\n",
      "0   196    242       3  881250949\n",
      "1   186    302       3  891717742\n",
      "2    22    377       1  878887116\n",
      "3   244     51       2  880606923\n",
      "4   166    346       1  886397596\n",
      "   movie              title\n",
      "0      1   Toy Story (1995)\n",
      "1      2   GoldenEye (1995)\n",
      "2      3  Four Rooms (1995)\n",
      "3      4  Get Shorty (1995)\n",
      "4      5     Copycat (1995)\n",
      "   user  movie  rating  timestamp                       title\n",
      "0   196    242       3  881250949                Kolya (1996)\n",
      "1   186    302       3  891717742    L.A. Confidential (1997)\n",
      "2    22    377       1  878887116         Heavyweights (1994)\n",
      "3   244     51       2  880606923  Legends of the Fall (1994)\n",
      "4   166    346       1  886397596         Jackie Brown (1997)\n"
     ]
    }
   ],
   "source": [
    "path = untar_data(URLs.ML_100k)\n",
    "ratings = pd.read_csv(path/'u.data', delimiter=\"\\t\", header=None, names = ['user','movie','rating','timestamp'])\n",
    "movies = pd.read_csv(path/'u.item',  delimiter='|', encoding='latin-1', usecols=(0,1), names=('movie','title'), header=None)\n",
    "print(ratings.head())\n",
    "print(movies.head())\n",
    "ratings = ratings.merge(movies)\n",
    "print(ratings.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f2f9d-42b0-466b-b36c-cd1c2afc1bba",
   "metadata": {},
   "source": [
    "### If we knew a latent factor\n",
    "If we knew for each user to what degree they liked each movie category, then we could calculate this info for each movie. E.g., if we had three categories (science-fiction, action, and old movies), we could rate each film as matching the categories (e.g., from -1 to +1) and also calculate category-preference \"profile\" for each user (from -1 to +1). Then we could compare them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "236f01ee-9639-49a5-964b-5ff70adfe04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1420000000000003\n",
      "-1.611\n"
     ]
    }
   ],
   "source": [
    "last_skywalker = np.array([0.98, 0.9, -0.9])  # categories matching for movie1\n",
    "casablanca = np.array([-0.99, -0.3, 0.8])  # categories matching for movie2\n",
    "user1 = np.array([0.9, 0.8, -0.6])  # category-preferences profile for user1\n",
    "print((user1 * last_skywalker).sum())  # dot product: 2.142 (meaning hight preference, probably user1 will like movie1)\n",
    "print((user1 * casablanca).sum())  # dot product: -1.611 (meaning low preference, probably user1 will not like movie2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a66073c-92bc-4308-90aa-e7b26ce5b3c6",
   "metadata": {},
   "source": [
    "## Method 1: Build own model 1\n",
    "### Learning the Latent Factors\n",
    "Since in our case we don't know what the latent factors actually are, and we don't know how to score them for each user and movie, we should learn them.  \n",
    "The major example in the Excel in Lecture 07 (starts from 01:09).  \n",
    "\n",
    "**Creating the DataLoaders**  \n",
    "By default, it takes the first column for the user, the second column for the item (here our movies), and the third column for the ratings. We need to change the value of item_name in our case to use the titles instead of the IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1fff793-ea62-4a4d-9f90-87693e256b13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>782</td>\n",
       "      <td>Starship Troopers (1997)</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>943</td>\n",
       "      <td>Judge Dredd (1995)</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>758</td>\n",
       "      <td>Mission: Impossible (1996)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94</td>\n",
       "      <td>Farewell My Concubine (1993)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23</td>\n",
       "      <td>Psycho (1960)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>296</td>\n",
       "      <td>Secrets &amp; Lies (1996)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>940</td>\n",
       "      <td>American President, The (1995)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>334</td>\n",
       "      <td>Star Trek VI: The Undiscovered Country (1991)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>380</td>\n",
       "      <td>Braveheart (1995)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>690</td>\n",
       "      <td>So I Married an Axe Murderer (1993)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = CollabDataLoaders.from_df(ratings, item_name='title', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97b51a4-e755-496d-9fd3-93e80b368a2c",
   "metadata": {},
   "source": [
    "We can represent our movie and user latent factor tables as simple matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9afbbe99-08db-4fd6-8a0b-0aab5b3e3233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.0827,  0.2138,  0.9310, -0.2739, -0.4359],\n",
      "        [-0.5195,  0.7613, -0.4365,  0.1365,  1.3300],\n",
      "        [-1.2804,  0.0705,  0.6489, -1.2110,  1.8266],\n",
      "        ...,\n",
      "        [ 0.8009, -0.4734, -0.8962, -0.7348, -0.0246],\n",
      "        [ 0.3354, -0.8262, -0.1541,  0.4699,  0.4873],\n",
      "        [ 2.4054, -0.2156, -1.4126, -0.2467,  1.0571]])\n",
      "tensor([[-0.3978,  0.4563,  1.2301,  0.3745,  0.9689],\n",
      "        [-1.1836, -0.5818, -0.5587, -0.4316,  0.2128],\n",
      "        [ 0.0420,  1.3201, -0.7999,  1.1123, -0.7585],\n",
      "        ...,\n",
      "        [ 2.4743,  1.3068,  0.4540,  0.6958,  0.5228],\n",
      "        [ 2.3970, -0.2559, -1.7196,  1.0440, -0.2662],\n",
      "        [ 0.2786, -0.6593,  0.5260, -0.3416, -1.3938]])\n"
     ]
    }
   ],
   "source": [
    "n_users = len(dls.classes[\"user\"])  # n of users is how many users there are\n",
    "n_movies = len(dls.classes[\"title\"])  # n of items is how many items there are\n",
    "n_factors = 5  # this is just Jeremy's intuition that works well\n",
    "\n",
    "user_factors = torch.randn(n_users, n_factors)\n",
    "movie_factors = torch.randn(n_movies, n_factors)\n",
    "print(user_factors)\n",
    "print(movie_factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c0fc60-0993-45a6-a557-b46960419d10",
   "metadata": {},
   "source": [
    "### Creating a new PyTorch module\n",
    "The input of the model is a tensor of shape batch_size x 2, where the first column (x[:, 0]) contains the user IDs and the second column (x[:, 1]) contains the movie IDs. As explained before, we use the embedding layers to represent our matrices of user and movie latent factors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a619fdf1-89c6-4836-a732-c8aa408f4b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProduct(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        return (users * movies).sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aaba0f-433b-42ee-9082-76195b8071bf",
   "metadata": {},
   "source": [
    "Now that we have defined our architecture, and created our parameter matrices, we need to create a Learner to optimize our model. Since we are doing things from scratch here, we will use the plain Learner class. After this, we are now ready to fit our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050b5349-1672-43f8-a9bf-db931206fe8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.355056</td>\n",
       "      <td>1.308388</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.032619</td>\n",
       "      <td>1.099086</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.881544</td>\n",
       "      <td>0.985998</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.760961</td>\n",
       "      <td>0.901010</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.746256</td>\n",
       "      <td>0.880025</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProduct(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62746a03-c7c2-4223-86d4-650c9d9b85a3",
   "metadata": {},
   "source": [
    "### Improving the model: adding sigmoid and biases\n",
    "(range from 0 to 5.5 is because sigmoid of 1 will never hit 1, but we need 5, right? So 5.5 by sigmoid will give 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "682c0145-2032-4595-b118-7ac3c10a72b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = Embedding(n_users, n_factors)\n",
    "        self.user_bias = Embedding(n_users, 1)\n",
    "        self.movie_factors = Embedding(n_movies, n_factors)\n",
    "        self.movie_bias = Embedding(n_movies, 1)\n",
    "        self.y_range = y_range  # this is the range the sigmoid will squash the results by.\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors(x[:,0])\n",
    "        movies = self.movie_factors(x[:,1])\n",
    "        res = (users * movies).sum(dim=1, keepdim=True)\n",
    "        res += self.user_bias(x[:,0]) + self.movie_bias(x[:,1])  # add biases for user and for movie\n",
    "        return sigmoid_range(res, *self.y_range)  # add sigmoid to final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a4a8b35-77b7-4991-be2a-f45dc98c3c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.313619</td>\n",
       "      <td>1.311592</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.059954</td>\n",
       "      <td>1.122256</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.923760</td>\n",
       "      <td>1.001304</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.820529</td>\n",
       "      <td>0.920403</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.796360</td>\n",
       "      <td>0.893080</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProduct(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16451910-34db-479e-acef-35cf36575dbc",
   "metadata": {},
   "source": [
    "### Weight decay\n",
    "We think we might be overfitting. Let's do L2 regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7cac31c-7887-4292-a8d9-5ca21ff5f8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.918345</td>\n",
       "      <td>0.949725</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.675732</td>\n",
       "      <td>0.895881</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508346</td>\n",
       "      <td>0.871886</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.465301</td>\n",
       "      <td>0.864229</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.442191</td>\n",
       "      <td>0.859740</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)  # add lamda here, try different values 0.1,0.01... that's it o____O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4067b23-1799-47b7-a056-08cfc3a548f2",
   "metadata": {},
   "source": [
    "## Method 2: Build own model 2\n",
    "So far, we've used Embedding without thinking about how it really works. Let's re-create DotProductBias without using this class. We'll need a randomly initialized weight matrix for each of the embeddings. \n",
    "\n",
    "We have to be careful: optimizers require that they can get all the parameters of a module from the module's parameters method. However, this does not happen fully automatically. If we just add a tensor as an attribute to a Module, it will not be included in parameters. To tell Module that we want to treat a tensor as a parameter, we have to wrap it in the nn.Parameter class. This class doesn't actually add any functionality (other than automatically calling requires_grad_ for us). It's only used as a \"marker\" to show what to include in parameters. \n",
    "\n",
    "We can create a tensor as a parameter, with random initialization. Then we will use this to create DotProductBias again, but without Embedding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa300e3d-4167-4f59-86c9-2c280b1e85d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_params(size):\n",
    "    return nn.Parameter(torch.zeros(*size).normal_(0, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f73365d2-9308-42ae-be3f-91a86a95d97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DotProductBias(Module):\n",
    "    def __init__(self, n_users, n_movies, n_factors, y_range=(0,5.5)):\n",
    "        self.user_factors = create_params([n_users, n_factors])\n",
    "        self.user_bias = create_params([n_users])\n",
    "        self.movie_factors = create_params([n_movies, n_factors])\n",
    "        self.movie_bias = create_params([n_movies])\n",
    "        self.y_range = y_range\n",
    "        \n",
    "    def forward(self, x):\n",
    "        users = self.user_factors[x[:,0]]\n",
    "        movies = self.movie_factors[x[:,1]]\n",
    "        res = (users*movies).sum(dim=1)\n",
    "        res += self.user_bias[x[:,0]] + self.movie_bias[x[:,1]]\n",
    "        return sigmoid_range(res, *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd1ade2e-b740-4440-8d87-7b809ec86a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.844252</td>\n",
       "      <td>0.937136</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.688366</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.519066</td>\n",
       "      <td>0.876162</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.453932</td>\n",
       "      <td>0.855043</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.437529</td>\n",
       "      <td>0.851891</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = DotProductBias(n_users, n_movies, 50)\n",
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42dfa8a-c1d3-45cc-a4e9-3fa07085c352",
   "metadata": {},
   "source": [
    "## Method 3: Use a fastai.collab\n",
    "We can create and train a collaborative filtering model using the exact structure shown earlier by using fastai's collab_learner:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "be309d17-8952-4c7b-87cb-12ef468a58bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.902238</td>\n",
       "      <td>0.950396</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.687878</td>\n",
       "      <td>0.897314</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.533113</td>\n",
       "      <td>0.869954</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.459932</td>\n",
       "      <td>0.856269</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.433415</td>\n",
       "      <td>0.852636</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = collab_learner(dls, n_factors=50, y_range=(0, 5.5))\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ad41d7f-e14c-4fab-b28b-bb2e68329743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EmbeddingDotBias(\n",
       "  (u_weight): Embedding(944, 50)\n",
       "  (i_weight): Embedding(1665, 50)\n",
       "  (u_bias): Embedding(944, 1)\n",
       "  (i_bias): Embedding(1665, 1)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print names of the layers:\n",
    "learn.model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f160e92-c11c-46f8-904c-9d6be8edd407",
   "metadata": {},
   "source": [
    "## Interpreting\n",
    "### Visulising the bias (interpreting the biases)\n",
    "It is interesting to see what parameters the model has discovered. Biases are like intercepts in lmm, meaning that they show the influence of factors independently of IV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44c17be8-ddb7-4d07-b897-bbda4ee46c50",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EmbeddingDotBias' object has no attribute 'movie_bias'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# for method 2:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m movie_bias = \u001b[43mlearn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmovie_bias\u001b[49m.squeeze()\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# the lowest rating\u001b[39;00m\n\u001b[32m      6\u001b[39m idxs = movie_bias.argsort()[:\u001b[32m10\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Code/fast_ai/.venv/lib/python3.13/site-packages/torch/nn/modules/module.py:1962\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1960\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[32m   1961\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[32m-> \u001b[39m\u001b[32m1962\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[32m   1963\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m object has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1964\u001b[39m )\n",
      "\u001b[31mAttributeError\u001b[39m: 'EmbeddingDotBias' object has no attribute 'movie_bias'"
     ]
    }
   ],
   "source": [
    "# for method 2:\n",
    "\n",
    "movie_bias = learn.model.movie_bias.squeeze()\n",
    "\n",
    "# the lowest rating\n",
    "idxs = movie_bias.argsort()[:10]\n",
    "print([dls.classes['title'][i] for i in idxs])\n",
    "\n",
    "# the highest ratings\n",
    "idxs = movie_bias.argsort(descending=True)[:10]\n",
    "print([dls.classes['title'][i] for i in idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "712f58f4-577c-4f5c-9220-e3a585ac72b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Showgirls (1995)', 'Children of the Corn: The Gathering (1996)', 'Grease 2 (1982)', 'Spice World (1997)', 'Cable Guy, The (1996)', 'Bio-Dome (1996)', \"Amityville 1992: It's About Time (1992)\", 'Lawnmower Man 2: Beyond Cyberspace (1996)', 'Amityville II: The Possession (1982)', 'Free Willy 2: The Adventure Home (1995)']\n",
      "['Shawshank Redemption, The (1994)', 'Titanic (1997)', \"Schindler's List (1993)\", 'Good Will Hunting (1997)', 'L.A. Confidential (1997)', 'Rear Window (1954)', 'Vertigo (1958)', 'Star Wars (1977)', 'To Kill a Mockingbird (1962)', 'Usual Suspects, The (1995)']\n"
     ]
    }
   ],
   "source": [
    "# for method 3:\n",
    "\n",
    "movie_bias = learn.model.i_bias.weight.squeeze()\n",
    "\n",
    "# the lowest rating\n",
    "idxs = movie_bias.argsort()[:10]\n",
    "print([dls.classes['title'][i] for i in idxs])\n",
    "\n",
    "# the highest ratings\n",
    "idxs = movie_bias.argsort(descending=True)[:10]\n",
    "print([dls.classes['title'][i] for i in idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f03ce9-29e4-41f3-874b-ae545cc1c4b1",
   "metadata": {},
   "source": [
    "### Embedding Distance\n",
    "On a two-dimensional map we can calculate the distance between two coordinates using the formula of Pythagoras (assuming that x and y are the distances between the coordinates on each axis). For a 50-dimensional embedding we can do exactly the same thing, except that we add up the squares of all 50 of the coordinate distances.\n",
    "\n",
    "If there were two movies that were nearly identical, then their embedding vectors would also have to be nearly identical, because the users that would like them would be nearly exactly the same. There is a more general idea here: movie similarity can be defined by the similarity of users that like those movies. And that directly means that the distance between two movies' embedding vectors can define that similarity. We can use this to find the most similar movie to Silence of the Lambs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "269890a7-8eac-482b-86e7-ffafdd374957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ready to Wear (Pret-A-Porter) (1994)'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (it seemed not working correctly even on the j's computer)\n",
    "movie_factors = learn.model.i_weight.weight\n",
    "idx = dls.classes['title'].o2i['Silence of the Lambs, The (1991)']\n",
    "distances = nn.CosineSimilarity(dim=1)(movie_factors, movie_factors[idx][None])\n",
    "idx = distances.argsort()[1]\n",
    "dls.classes['title'][idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb9ebb7-6dac-458f-9b0c-baeda50bce6c",
   "metadata": {},
   "source": [
    "## Method 4: DL model 1\n",
    "Our dot product model works quite well, and it is the basis of many successful real-world recommendation systems. This approach to collaborative filtering is known as probabilistic matrix factorization (PMF). Another approach, which generally works similarly well given the same data, is deep learning.\n",
    "\n",
    "To turn our architecture into a deep learning model, the first step is to take the results of the embedding lookup and concatenate those activations together. This gives us a matrix which we can then pass through linear layers and nonlinearities in the usual way.\n",
    "\n",
    "Since we'll be concatenating the embeddings, rather than taking their dot product, the two embedding matrices can have different sizes (i.e., different numbers of latent factors). fastai has a function get_emb_sz that returns recommended sizes for embedding matrices for your data, based on a heuristic that fast.ai has found tends to work well in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "35843c31-aa85-413f-871f-31c6fa9cf82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(944, 74), (1665, 102)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get sizes dor embedding matrices\n",
    "embs = get_emb_sz(dls)\n",
    "embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "99e2d10a-2fcb-476b-8361-6eafdcdba526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the class\n",
    "class CollabNN(Module):\n",
    "    def __init__(self, user_sz, item_sz, y_range=(0,5.5), n_act=100):\n",
    "        self.user_factors = Embedding(*user_sz)\n",
    "        self.item_factors = Embedding(*item_sz)\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(user_sz[1]+item_sz[1], n_act),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(n_act, 1))\n",
    "        self.y_range = y_range\n",
    "\n",
    "    def forward(self, x):\n",
    "        embs = self.user_factors(x[:,0]),self.item_factors(x[:,1])\n",
    "        x = self.layers(torch.cat(embs, dim=1))\n",
    "        return sigmoid_range(x, *self.y_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5f5ece8d-790b-478a-9231-0f52d9d67b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the class to create the model\n",
    "model = CollabNN(*embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cfefa850-ba0a-4fe2-a6b5-56677d2f4341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.929937</td>\n",
       "      <td>0.946122</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.851822</td>\n",
       "      <td>0.912206</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.838512</td>\n",
       "      <td>0.881456</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.779626</td>\n",
       "      <td>0.870814</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.731197</td>\n",
       "      <td>0.862495</td>\n",
       "      <td>00:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = Learner(dls, model, loss_func=MSELossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474de600-bf09-4586-98cb-af13dff1dc72",
   "metadata": {},
   "source": [
    "### Method 4: DL model 2\n",
    "fastai provides this model in fastai.collab if you pass use_nn=True in your call to collab_learner (including calling get_emb_sz for you), and it lets you easily create more layers. For instance, here we're creating two hidden layers, of size 100 and 50, respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "19265a13-6e65-4926-81a6-cbbf1586a884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.981596</td>\n",
       "      <td>0.978487</td>\n",
       "      <td>00:09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.904838</td>\n",
       "      <td>0.918161</td>\n",
       "      <td>00:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.829316</td>\n",
       "      <td>0.875605</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.774758</td>\n",
       "      <td>0.859824</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.752902</td>\n",
       "      <td>0.861667</td>\n",
       "      <td>00:07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = collab_learner(dls, use_nn=True, y_range=(0, 5.5), layers=[100,50])\n",
    "learn.fit_one_cycle(5, 5e-3, wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e81fd1d-8179-44be-a9df-97303d65eaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a660b20-785e-47ca-b289-bb439f31b140",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
